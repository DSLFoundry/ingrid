package premun.mps.ingrid.parser;

import premun.mps.ingrid.parser.grammar.*;
import premun.mps.ingrid.parser.grammar.exception.*;

import java.util.*;

/**
 * Class operates on a rule set generated by ANTLR parser.
 */
public class GrammarResolver {
    /**
     * Resolves rules that weren't resolved during first parsing. That means
     * that everything that was discovered during first walk and is saved as
     * a string name will be replaced by reference to the this.rules element.
     * Flattens lexer rules so that they become either strings or regexes.
     *
     * @param parserResult Result of ANTLR parsing.
     * @return Resolved grammar ready to be imported to MPS.
     */
    public static GrammarInfo generateGrammar(ParserResult parserResult) throws IngridParserException {
        GrammarInfo grammar = new GrammarInfo(parserResult.grammarName);

        Map<String, Rule> rules = parserResult.rules;

        // Lexer rules must be resolved first so that parser rules can reference them
        // Lexer rules do not contain references to parser rules
        // We need to copy the array because we are changing it inside forEach
        new ArrayList<>(rules.keySet())
            .stream()
            .filter(name -> rules.get(name) instanceof LexerRule)
            .forEach(name -> {
                FlatLexerRule flatRule = null;
                // We always get updated Rule from rule set again, because we might have updated it
                flatRule = flattenLexerRule(rules.get(name), rules);
                grammar.rules.put(name, flatRule);
            });

        // We need to copy the array because we are changing it inside forEach
        new ArrayList<>(rules.values())
            .stream()
            .filter(r -> r instanceof ParserRule)
            .forEach(rule -> {
                resolveParserRule((ParserRule) rule, rules);
                grammar.rules.put(rule.name, rule);
            });

        grammar.rootRule = grammar.rules.get(parserResult.rootRule);

        return grammar;
    }

    /**
     * Matches (string) references inside rule alternatives with actual
     * pointers to rule definitions.
     *
     * @param rule Rule to be resolved
     */
    private static void resolveParserRule(ParserRule rule, Map<String, Rule> rules) throws IngridParserException {
        // For each alternative line..
        for (List<RuleReference> alternative : rule.alternatives) {
            // For each element on the line..
            for (int i = 0; i < alternative.size(); ++i) {
                RuleReference ref = alternative.get(i);

                // Rule referenced in this alternative element
                Rule r = ref.rule;

                if (r instanceof UnresolvedRule) {
                    // Lexer rules were resolved first, so they are ready to be referenced
                    if (rules.containsKey(r.name)) {
                        Rule lookedUpRule = rules.get(r.name);
                        alternative.set(i, new RuleReference(lookedUpRule, ref.quantity));
                    } else {
                        throw new IngridParserException(
                            "Couldn't resolve rule '" + r.name + "' (inside " + rule.name + ")");
                    }
                } else if (r instanceof QuantifierRule) {
                    if (i == 0) {
                        throw new IngridParserException(
                            "Quantifier suffix found with no previous reference");
                    }

                    // Apply quantifier to previous element of alternative
                    alternative.get(i - 1).quantity = ((QuantifierRule) r).quantity;
                    // Remove quantifier itself
                    alternative.remove(i);
                    i--;
                }
            }
        }
    }

    /**
     * Flattens rule into a regex or string literal.
     * TODO: Cyclic (faulty) ANTLR definition will cause endless loop and stack overflow.
     *
     * @param rule Rule to be resolved.
     * @param rules All rules that can be used for lookup.
     */
    private static FlatLexerRule flattenLexerRule(Rule rule, Map<String, Rule> rules) {
        // Because some rules were resolved as a dependency of another rule,
        // it might happen that it is already flattened.
        if (rule instanceof FlatLexerRule) {
            return (FlatLexerRule) rule;
        }

        if (rule instanceof UnresolvedLexerRule) {
            throw new IngridParserException(
                "Rule '" + rule.name + "' must be resolved before flattening");
        }

        LexerRule lexerRule = (LexerRule) rule;

        // If we have only one element, we might be looking at a literal rule..
        // We count all elements of all alternatives:
        if (lexerRule.alternatives.size() == 1 && lexerRule.alternatives.get(0).size() == 1) {
            Rule only = lexerRule.alternatives.get(0).get(0);
            if (only instanceof LiteralRule) {
                return new LiteralRule(rule.name, ((LiteralRule) only).value);
            }
        }

        // We can construct one big regex out of sub rules
        List<List<String>> regexs = new ArrayList<>();

        // Gather all sub rule contents (or resolve them, if wasn't resolved before)
        for (List<Rule> alternative : lexerRule.alternatives) {
            List<String> subRegex = new ArrayList<>();

            for (Rule element : alternative) {
                // Is each sub element already resolved?
                if (!(element instanceof FlatLexerRule)) {
                    if (element instanceof QuantifierRule) {
                        int lastIndex = subRegex.size() - 1;

                        if (lastIndex < 0) {
                            throw new IngridParserException("Quantifier suffix found with no prefix regex");
                        }

                        // We append it to the previous rule
                        String quantifier = ((QuantifierRule) element).quantity.toString();
                        String quantifiedRegex = '(' + subRegex.get(lastIndex) + ')' + quantifier;
                        subRegex.set(lastIndex, quantifiedRegex);

                    } else if (element instanceof UnresolvedLexerRule) {
                        if (!rules.containsKey(element.name)) {
                            throw new UnresolvableRuleException("Failed to resolve lexer rule '" + element.name + "'");
                        }

                        FlatLexerRule flatRule = flattenLexerRule(rules.get(element.name), rules);
                        rules.put(element.name, flatRule);
                        subRegex.add(flatRule.getContent());
                    } else {
                        throw new IngridParserException(
                            "Rule '" + element.name + "' (" + element.getClass().getSimpleName() + ") failed to be flattened");
                    }
                } else {
                    subRegex.add(((FlatLexerRule) element).getContent());
                }
            }

            regexs.add(subRegex);
        }

        // Build regex from gathered strings
        return new RegexRule(rule.name, buildLexerRegex(regexs));
    }

    /**
     * Helper method that turns {{a,b,c}, {d,e}} into ((a|b|c)|(d|e)).
     *
     * @param alternatives Array of arrays of strings.
     * @return Flattened string ready for regex.
     */
    private static String buildLexerRegex(List<List<String>> alternatives) {
        StringBuilder expression = new StringBuilder();

        if (alternatives.size() == 1) {
            expression.append(String.join("", alternatives.get(0)));
        } else {
            for (List<String> alt : alternatives) {
                if (expression.length() == 0) {
                    expression.append('(');
                } else {
                    expression.append('|');
                }

                expression
                    .append('(')
                    .append(String.join("", alt))
                    .append(')');
            }

            expression.append(')');
        }

        return expression.toString();
    }
}
